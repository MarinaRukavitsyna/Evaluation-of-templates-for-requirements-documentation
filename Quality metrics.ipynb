{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "import syllapy # https://pypi.org/project/syllapy/\n",
    "import readability # https://pypi.org/project/readability/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSheets = pd.read_excel('template_comparison-tss-evs_python.xlsx', sheet_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add syllables\n",
    "def count_syllables(text):\n",
    "    text_no_digit = ''.join([i for i in text if not i.isdigit()])\n",
    "    syllablesCount = syllapy.count(text_no_digit)\n",
    "    \n",
    "    return syllablesCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add definite_articles?  (IR5,SR10-11)\n",
    "def if_definite_articles(text): \n",
    "    article_terms = ['a']  \n",
    "    \n",
    "    doc = nlp(text.lower()) \n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text in article_terms:\n",
    "            return 0  \n",
    "     \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_nominalization? (SR3)\n",
    "def no_nominalization(text):    \n",
    "    result = readability.getmeasures(text, lang='en')['word usage']['nominalization']\n",
    "    return (1 if result == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_comparison? (SR8,Rupp09)\n",
    "# Add clear_comparison? (SR8) - evaluate cells with '0' manually\n",
    "\n",
    "def no_comparison(text):\n",
    "    doc = nlp(text) \n",
    "    for token in doc:\n",
    "        if (token.tag_ == \"RBR\" or token.tag_ == \"JJR\"): \n",
    "            return 0        \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add units? (IR6) - evaluate cells with '0' manually\n",
    "def correct_units(text):\n",
    "    for i in text:\n",
    "        if i.isdigit():\n",
    "            return 0\n",
    "        \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_vague_terms? (IR7,SR2+12,E106)\n",
    "def no_vague_terms(text):\n",
    "    vague_terms_simple = ['some', 'any', 'allowable ', 'several', 'many', 'nearly ', 'about', 'almost',\n",
    "                          'approximate', 'ancillary','relevant', 'routine', 'common', 'generic', 'significant', \n",
    "                          'flexible', 'expandable', 'typical', 'sufficient', 'adequate', 'appropriate', 'efficient', \n",
    "                          'effective', 'proficient', 'reasonable', 'customary', 'usually', 'approximately', \n",
    "                          'sufficiently', 'typically']  \n",
    "    vague_terms_complex = ['a lot of', 'a few', 'almost always', 'very nearly',  'close to'] \n",
    "    \n",
    "    doc = nlp(text.lower())     \n",
    "    for token in doc:\n",
    "        if token.text in vague_terms_simple:\n",
    "            return 0  \n",
    "     \n",
    "    result = [word for word in vague_terms_complex if(word in text.lower())] \n",
    "    \n",
    "    return (0 if bool(result) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_escape_clause? (IR8)\n",
    "def no_escape_clause(text):\n",
    "    escape_clause = ['so far as is possible', 'as little as possible', 'where possible', \n",
    "                     'as much as possible', 'if it should prove necessary', 'if necessary', \n",
    "                     'to the extent necessary', 'as appropriate', 'as required', \n",
    "                     'to the extent practical', 'if practicable']  \n",
    "    \n",
    "    result = [word for word in escape_clause if(word in text.lower())] \n",
    "    \n",
    "    return (0 if bool(result) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_open_end? (IR9)\n",
    "def no_open_end(text):    \n",
    "    open_end_terms_simple = ['etc']  \n",
    "    open_end_terms_complex = ['and so on', 'including but not limited to']  \n",
    "    \n",
    "    doc = nlp(text.lower())     \n",
    "    for token in doc:\n",
    "        if token.text in open_end_terms_simple:\n",
    "            return 0  \n",
    "     \n",
    "    result = [word for word in open_end_terms_complex if(word in text.lower())] \n",
    "    \n",
    "    return (0 if bool(result) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_superfluous_infinitives? (IR10)\n",
    "def no_superfluous_infinitives(text):\n",
    "    superfluous_infinitives = ['be designed', 'be able to', 'be capable to', 'be capable of']  \n",
    "    \n",
    "    result = [word for word in superfluous_infinitives if(word in text.lower())] \n",
    "    \n",
    "    return (0 if bool(result) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_negation? (IR16,E106)\n",
    "def no_negation(text):\n",
    "    negation_terms = ['not']  \n",
    "    \n",
    "    doc = nlp(text.lower()) \n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text in negation_terms:\n",
    "            return 0  \n",
    "     \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_combinators? (IR19,SR9,E106)\n",
    "def no_combinators(text):\n",
    "    combinator_terms_simple = ['and', 'or', 'then', 'unless', 'but', 'however', 'also','whether', 'meanwhile',\n",
    "                               'whereas', 'otherwise']  \n",
    "    combinator_terms_complex = ['as well as', 'but also', 'on the other hand', ]  \n",
    "    \n",
    "    doc = nlp(text.lower())     \n",
    "    for token in doc:\n",
    "        if token.text in combinator_terms_simple:\n",
    "            return 0  \n",
    "     \n",
    "    result = [word for word in combinator_terms_complex if(word in text.lower())] \n",
    "    \n",
    "    return (0 if bool(result) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add clear_quantifiers? (IR32+34,SR8+10-11,E106) - evaluate cells with '0' manually\n",
    "def clear_quantifiers(text):\n",
    "    quantifiers_terms = ['all', 'any', 'both”']  \n",
    "    \n",
    "    doc = nlp(text.lower()) \n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text in quantifiers_terms:\n",
    "            print(token.text)\n",
    "            return 0  \n",
    "     \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_absolutes? (IR26) - evaluate cells with '0' manually\n",
    "def no_absolutes(text):\n",
    "    absolutes_terms = ['100%', '100 %', 'all', 'always', 'never']  \n",
    "    \n",
    "    doc = nlp(text.lower()) \n",
    "    \n",
    "    for token in doc:\n",
    "        if token.text in absolutes_terms:\n",
    "            return 0  \n",
    "     \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add no_pronouns? (IR24)\n",
    "def no_pronouns(text):\n",
    "    doc = nlp(text.lower()) \n",
    "    for token in doc:\n",
    "        if (token.pos_ == \"PRON\"):\n",
    "            return 0        \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fake 1 - evaluate cells with '0' manually\n",
    "def add_fake(text):    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there\n",
      "it\n",
      "there\n",
      "it\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "there\n",
      "it\n",
      "there\n",
      "it\n",
      "it\n",
      "it\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "there\n",
      "it\n",
      "there\n",
      "it\n",
      "it\n",
      "always\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "there\n",
      "there\n",
      "it\n",
      "always\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "there\n",
      "there\n",
      "it\n",
      "always\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "there\n",
      "there\n",
      "it\n",
      "always\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "there\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "all\n",
      "all\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "all\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "themselves\n",
      "they\n",
      "herself\n",
      "them\n",
      "they\n",
      "there\n",
      "it\n",
      "it\n",
      "it\n",
      "who\n",
      "nobody\n",
      "nobody\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "there\n",
      "you\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "never\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "themselves\n",
      "they\n",
      "herself\n",
      "them\n",
      "them\n",
      "they\n",
      "there\n",
      "it\n",
      "it\n",
      "it\n",
      "who\n",
      "nobody\n",
      "nobody\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "there\n",
      "you\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "never\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "themselves\n",
      "they\n",
      "themselves\n",
      "them\n",
      "them\n",
      "they\n",
      "they\n",
      "it\n",
      "it\n",
      "it\n",
      "who\n",
      "nobody\n",
      "nobody\n",
      "it\n",
      "it\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "never\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "themselves\n",
      "they\n",
      "herself\n",
      "them\n",
      "them\n",
      "they\n",
      "they\n",
      "it\n",
      "it\n",
      "it\n",
      "who\n",
      "nobody\n",
      "nobody\n",
      "it\n",
      "it\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "never\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "themselves\n",
      "they\n",
      "herself\n",
      "them\n",
      "them\n",
      "they\n",
      "they\n",
      "it\n",
      "it\n",
      "it\n",
      "who\n",
      "nobody\n",
      "nobody\n",
      "it\n",
      "it\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "never\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "themselves\n",
      "they\n",
      "themselves\n",
      "them\n",
      "them\n",
      "they\n",
      "they\n",
      "it\n",
      "it\n",
      "it\n",
      "who\n",
      "nobody\n",
      "nobody\n",
      "it\n",
      "it\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "never\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "it\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "always\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "all\n",
      "any\n"
     ]
    }
   ],
   "source": [
    "for dfName, df in dfSheets.items():\n",
    "    df[\"#syllables\"] = df[\"Text\"].apply(count_syllables)\n",
    "    df[\"definite_articles?  (IR5,SR10-11)\"] = df[\"Text\"].apply(if_definite_articles)\n",
    "    df[\"no_nominalization? (SR3)\"] = df[\"Text\"].apply(no_nominalization)\n",
    "    # Add clear_comparison? (SR8) - evaluate cells with '0' manually\n",
    "    df[\"no_comparison? (SR8,Rupp09)\"] = df[\"clear_comparison? (SR8)\"] = df[\"Text\"].apply(no_comparison)\n",
    "    df[\"units? (IR6)\"] = df[\"Text\"].apply(correct_units) #  - evaluate cells with '0' manually\n",
    "    df[\"no_vague_terms? (IR7,SR2+12,E106)\"] = df[\"Text\"].apply(no_vague_terms)\n",
    "    df[\"no_escape_clause? (IR8)\"] = df[\"Text\"].apply(no_escape_clause)\n",
    "    df[\"no_open_end? (IR9)\"] = df[\"Text\"].apply(no_open_end)\n",
    "    df[\"no_superfluous_infinitives? (IR10)\"] = df[\"Text\"].apply(no_superfluous_infinitives)\n",
    "    df[\"no_negation? (IR16,E106)\"] = df[\"Text\"].apply(no_negation)\n",
    "    df[\"no_combinators? (IR19,SR9,E106)\"] = df[\"Text\"].apply(no_combinators)\n",
    "    \n",
    "    \n",
    "    df[\"no_pronouns? (IR24)\"] = df[\"Text\"].apply(no_pronouns)\n",
    "    # evaluate cells with '0' manually - print\n",
    "    df[\"no_absolutes? (IR26)\"] = df[\"Text\"].apply(no_absolutes)    \n",
    "    # evaluate cells with '0' manually\n",
    "    df[\"clear_quantifiers? (IR32+34,SR8+10-11,E106)\"] = df[\"Text\"].apply(clear_quantifiers)\n",
    "    \n",
    "    df[\"contextfree? (IR25,SR6-7+16-18,E106)\"] = df[\"Text\"].apply(add_fake)\n",
    "    df[\"no_groupnoun? (IR22,SR10-12)\"] = df[\"Text\"].apply(add_fake)\n",
    "    df[\"explicit_conditions? (IR27,SR11+16-18)\"] = df[\"Text\"].apply(add_fake)    \n",
    "    df[\"condition_combination_clear? (IR28,SR16-18)\"] = df[\"Text\"].apply(add_fake)    \n",
    "    df[\"solution_free? (IR31,E106)\"] = df[\"Text\"].apply(add_fake)\n",
    "    df[\"value_tolerance? (IR33,E106)\"] = df[\"Text\"].apply(add_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for dfName, df in dfSheets.items():\n",
    "    df.to_excel(writer, dfName)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('Kincaid', 13.629032258064516), ('ARI', 19.443225806451615), ('Coleman-Liau', 14.920093967741941), ('FleschReadingEase', 52.563548387096795), ('GunningFogIndex', 18.851612903225806), ('LIX', 60.03225806451613), ('SMOGIndex', 15.24744871391589), ('RIX', 9.0), ('DaleChallIndex', 13.323777419354839)])\n",
      "==============================\n",
      "OrderedDict([('characters_per_word', 5.387096774193548), ('syll_per_word', 1.4516129032258065), ('words_per_sentence', 31.0), ('sentences_per_paragraph', 1.0), ('type_token_ratio', 0.9032258064516129), ('characters', 167), ('syllables', 45), ('words', 31), ('wordtypes', 28), ('sentences', 1), ('paragraphs', 1), ('long_words', 9), ('complex_words', 5), ('complex_words_dc', 16)])\n",
      "==============================\n",
      "OrderedDict([('tobeverb', 1), ('auxverb', 1), ('conjunction', 2), ('pronoun', 0), ('preposition', 4), ('nominalization', 1)])\n",
      "==============================\n",
      "OrderedDict([('pronoun', 0), ('interrogative', 0), ('article', 1), ('subordination', 0), ('conjunction', 0), ('preposition', 0)])\n"
     ]
    }
   ],
   "source": [
    "text = ('The TSS shall provide assistants and supervisors with the ability to manage contracts. Manage means „CRUD“ (Create, Read, Update, Delete). Update and deletion of contracts is only possible in state PREPARED.')\n",
    "results = readability.getmeasures(text, lang='en')\n",
    "print(results['readability grades'])\n",
    "print(\"==============================\")\n",
    "print(results['sentence info'])\n",
    "print(\"==============================\")\n",
    "print(results['word usage'])\n",
    "print(\"==============================\")\n",
    "print(results['sentence beginnings'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
