{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_FScore(text):\n",
    "    # function to test if something is a noun\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    # function to test if something is a pronoun\n",
    "    is_pronoun = lambda pos: pos[:3] == 'PRP'\n",
    "    # function to test if something is an adjective\n",
    "    is_adj = lambda pos: pos[:2] == 'JJ'\n",
    "    # function to test if something is a preposition\n",
    "    is_prep = lambda pos: pos[:2] == 'IN'\n",
    "    # function to test if something is an article\n",
    "    is_article = lambda pos: pos[:2] == 'DT'\n",
    "    # function to test if something is a verb\n",
    "    is_verb = lambda pos: pos[:2] == 'VB'\n",
    "    # function to test if something is an adverb\n",
    "    is_adverb = lambda pos: pos[:2] == 'RB'\n",
    "    # function to test if something is a interjection\n",
    "    is_interj = lambda pos: pos[:2] == 'UH'\n",
    "\n",
    "    # do the nlp stuff\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
    "    pronouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_pronoun(pos)] \n",
    "    adjectives = [word for (word, pos) in nltk.pos_tag(tokenized) if is_adj(pos)] \n",
    "    prepositions = [word for (word, pos) in nltk.pos_tag(tokenized) if is_prep(pos)] \n",
    "    articles = [word for (word, pos) in nltk.pos_tag(tokenized) if is_article(pos)] \n",
    "    verbs = [word for (word, pos) in nltk.pos_tag(tokenized) if is_verb(pos)] \n",
    "    adverbs = [word for (word, pos) in nltk.pos_tag(tokenized) if is_adverb(pos)] \n",
    "    interjections = [word for (word, pos) in nltk.pos_tag(tokenized) if is_interj(pos)] \n",
    "\n",
    "    FScore = (len(nouns) + len(adjectives) + len(prepositions) + len(articles) - len(pronouns) - len(verbs) - len(adverbs) - len(interjections) + 100)/2\n",
    "      \n",
    "    return FScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSheets = pd.read_excel('Requirements_Documents.xlsx', sheet_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLEX free\n",
      "169.5\n",
      "FLEX EARS\n",
      "166.0\n",
      "FLEX MASTER\n",
      "184.0\n",
      "FLEX advEARS\n",
      "196.0\n",
      "FLEX boilerplates\n",
      "192.0\n",
      "FLEX boilerplates (DODT)\n",
      "183.0\n",
      "FLEX SPIDER\n",
      "160.5\n",
      "CS_E 50 free\n",
      "251.5\n",
      "CS_E 50 EARS\n",
      "249.0\n",
      "CS_E 50 MASTER\n",
      "243.5\n",
      "CS_E 50 advEARS\n",
      "265.5\n",
      "CS_E 50 boilerplates\n",
      "252.0\n",
      "CS_E 50 boilerplates (DODT)\n",
      "253.0\n",
      "CS_E 50 SPIDER\n",
      "260.5\n",
      "ECSS_E60-30 free\n",
      "289.0\n",
      "ECSS_E60-30 EARS\n",
      "259.0\n",
      "ECSS_E60-30 MASTER\n",
      "233.5\n",
      "ECSS_E60-30 advEARS\n",
      "238.5\n",
      "ECSS_E60-30 boilerplates\n",
      "269.0\n",
      "ECSS_E60-30 boilerplates (DODT)\n",
      "256.0\n",
      "ECSS_E60-30 SPIDER\n",
      "247.0\n",
      "TSS free\n",
      "400.0\n",
      "TSS EARS\n",
      "392.5\n",
      "TSS MASTER\n",
      "416.0\n",
      "TSS advEARS\n",
      "419.5\n",
      "TSS boilerplates\n",
      "422.5\n",
      "TSS boilerplates (DODT)\n",
      "422.5\n",
      "TSS SPIDER\n",
      "399.5\n",
      "EVS free\n",
      "577.0\n",
      "EVS EARS\n",
      "593.0\n",
      "EVS MASTER\n",
      "538.0\n",
      "EVS advEARS\n",
      "608.5\n",
      "EVS boilerplates\n",
      "616.5\n",
      "EVS boilerplates (DODT)\n",
      "555.0\n",
      "EVS SPIDER\n",
      "523.5\n"
     ]
    }
   ],
   "source": [
    "for dfName, df in dfSheets.items():\n",
    "    print(dfName)\n",
    "    corpus = ' '.join(df[\"Text\"])\n",
    "    FScore = calc_FScore(corpus) \n",
    "   \n",
    "    print(FScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
